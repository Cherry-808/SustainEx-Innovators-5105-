{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh1odnwrsRar",
        "outputId": "5902aa36-78dc-430b-8c36-89d03f891de4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/A_Group/final_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48so1ZWSsbuz",
        "outputId": "f0e371bf-b6e8-4b6c-8872-0af9f20085dc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BT4222_Group21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install ntlk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd_dtG2Npvhd",
        "outputId": "1b504933-39d1-4121-faeb-75bdd04fed89"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ntlk (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ntlk\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def pdfToText(pdfFilePath, outputFilePath):\n",
        "    print(f\"Processing {pdfFilePath}\")\n",
        "    # Open the PDF file\n",
        "    pdf_file = open(pdfFilePath, 'rb')\n",
        "\n",
        "    # Create a PDF reader object\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Initialize a string variable to hold the text\n",
        "    text = \"\"\n",
        "\n",
        "    # Iterate through all the pages and extract text\n",
        "    for page_num in range(num_pages):\n",
        "        page_obj = reader.pages[page_num]\n",
        "        text += page_obj.extract_text()\n",
        "\n",
        "    # Close the PDF file\n",
        "    pdf_file.close()\n",
        "\n",
        "    # Open the file in write mode\n",
        "    with open(outputFilePath, 'w') as f:\n",
        "        # Write the text to the file\n",
        "        f.write(text)\n",
        "\n",
        "    # Print a message to confirm that the file has been saved\n",
        "    print(f\"Text saved to {outputFilePath}.\")"
      ],
      "metadata": {
        "id": "2DPsTcW5sIqM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "def remove_non_english_chars(text):\n",
        "    # normalize text and check if ASCII value more than 128 (non-english words)\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
        "                   if unicodedata.category(c) != 'Mn' and\n",
        "                   ord(c) < 128)"
      ],
      "metadata": {
        "id": "oqcWEme8sI1U"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "\n",
        "if not os.path.exists(\"pdf_text\"):\n",
        "    os.makedirs(\"pdf_text\")\n",
        "\n",
        "\n",
        "input_filename = '../final_summary/2024_released_CGN_ESG_report.pdf'\n",
        "output_filename = '../final_summary/pdf_text/CGN_2023.csv'\n",
        "pdfToText(input_filename, output_filename)\n",
        "\n",
        "# read the text file\n",
        "with open(output_filename, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "# clean the data\n",
        "text = remove_non_english_chars(text)\n",
        "text = re.sub(r'\\n', ' ', text)  # remove line breaks\n",
        "text = re.sub(r'\\s+', ' ', text)  # remove multiple spaces\n",
        "sentences = nltk.sent_tokenize(text) # split the text into sentences\n",
        "processed_sentences = []\n",
        "for sentence in sentences:\n",
        "    sentence = re.sub(r\"\\d+\\n\", \"\", sentence) # Remove page number\n",
        "    sentence = re.sub(r\"\\n\", \" \", sentence) # Remove line breaks\n",
        "    sentence = re.sub(r\"\\.(\\s*\\.){1,}\", \". \", sentence) # Remove consecutive periods\n",
        "    split_sentences = re.split(\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)(?<!\\d\\.)\\s*(?=[A-Z])\", sentence) # split text into sentences\n",
        "\n",
        "    split_sentences = [s for s in split_sentences if s != \"\" and s != \".\"] # do not include empty sentences or \".\"\n",
        "    processed_sentences.extend(split_sentences)\n",
        "\n",
        "    # create a dataframe\n",
        "df = pd.DataFrame({'sentences': processed_sentences})\n",
        "df.to_csv(output_filename, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waLPyb9NsI93",
        "outputId": "5149274d-56bc-41ae-e279-9a863102ea29"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/data/2024_released_CGN_ESG_report.pdf\n",
            "Text saved to /content/drive/MyDrive/BT4222_Group21/pdf_text/CGN_2023.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mcmJsKbzZ0",
        "outputId": "933ffba0-2d74-45d4-b4b2-4ca06e0fdcef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install pytorch\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHeP236kbzZ1"
      },
      "source": [
        "### ESG-BERT\n",
        "- Domain Specific BERT Model for Text Mining in Sustainable Investing\n",
        "- URL: https://huggingface.co/nbroad/ESG-BERT\n",
        "- This pre-trained model is able to classify each text and returns a label number which correlates to a textual label:\n",
        "    * __label__Business_Ethics :  0\n",
        "    * __label__Data_Security :  1\n",
        "    * __label__Access_And_Affordability :  2\n",
        "    * __label__Business_Model_Resilience :  3\n",
        "    * __label__Competitive_Behavior :  4\n",
        "    * __label__Critical_Incident_Risk_Management :  5\n",
        "    * __label__Customer_Welfare :  6\n",
        "    * __label__Director_Removal :  7\n",
        "    * __label__Employee_Engagement_Inclusion_And_Diversity :  8\n",
        "    * __label__Employee_Health_And_Safety :  9\n",
        "    * __label__Human_Rights_And_Community_Relations :  10\n",
        "    * __label__Labor_Practices :  11\n",
        "    * __label__Management_Of_Legal_And_Regulatory_Framework :  12\n",
        "    * __label__Physical_Impacts_Of_Climate_Change :  13\n",
        "    * __label__Product_Quality_And_Safety :  14\n",
        "    * __label__Product_Design_And_Lifecycle_Management :  15\n",
        "    * __label__Selling_Practices_And_Product_Labeling :  16\n",
        "    * __label__Supply_Chain_Management :  17\n",
        "    * __label__Systemic_Risk_Management :  18\n",
        "    * __label__Waste_And_Hazardous_Materials_Management :  19\n",
        "    * __label__Water_And_Wastewater_Management :  20\n",
        "    * __label__Air_Quality :  21\n",
        "    * __label__Customer_Privacy :  22\n",
        "    * __label__Ecological_Impacts :  23\n",
        "    * __label__Energy_Management :  24\n",
        "    * __label__GHG_Emissions :  25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl8uolITbzZ3",
        "outputId": "00bb0b55-ad65-43a4-a06b-28cf07fec62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import math\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nbroad/ESG-BERT\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nbroad/ESG-BERT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I4tdM1kbzZ3"
      },
      "source": [
        "### Step 1: Mapping ESG-BERT's topics to SGX and S&P ESG Criteria Topics\n",
        "1. Using ESG-BERT to classify our SGX and S&P Global ESG Criteria Topics into its labels\n",
        "2. We only take the predict label with highest probability.\n",
        "3. For those labels without any SGX and S&P ESG Criteria Topics, we will manually map them ourselves based on relevancy\n",
        "\n",
        "`labels_to_criteria`\n",
        "- Key: ESG-BERT's ESG_Labels\n",
        "- Value: SGX and S&P Global ESG Criteria Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XenTm1SjbzZ3",
        "outputId": "909b6c90-21b2-4f06-f804-941b39c1426f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Physical_Impacts_Of_Climate_Change': ['Climate Strategy'],\n",
              " 'Business_Model_Resilience': ['Human Capital Development',\n",
              "  'Innovation Management'],\n",
              " 'Human_Rights_And_Community_Relations': ['Human Rights',\n",
              "  'Environmental Policy & Management Systems',\n",
              "  'Social Impacts on Communities',\n",
              "  'Stakeholder Engagement'],\n",
              " 'Data_Security': ['Information Security Cybersecurity & System Availability',\n",
              "  'Network Reliability'],\n",
              " 'Energy_Management': ['Operational Eco-Efficiency',\n",
              "  'Low Carbon Strategy',\n",
              "  'Energy Mix',\n",
              "  'Electricity Generation',\n",
              "  'Fuel Efficiency'],\n",
              " 'Product_Design_And_Lifecycle_Management': ['Product Stewardship',\n",
              "  'Packaging',\n",
              "  'Sustainable Marketing & Brand Perception',\n",
              "  'Sustainable Finance',\n",
              "  'Circular Fashion'],\n",
              " 'Supply_Chain_Management': ['Supply Chain Management'],\n",
              " 'Employee_Engagement_Inclusion_And_Diversity': ['Talent Attraction & Retention',\n",
              "  'Financial Inclusion'],\n",
              " 'Labor_Practices': ['Labor Practice Indicators'],\n",
              " 'Systemic_Risk_Management': ['Risk & Crisis Management',\n",
              "  'Decarbonization Strategy'],\n",
              " 'Product_Quality_And_Safety': ['Product Quality & Recall Management'],\n",
              " 'Management_Of_Legal_And_Regulatory_Framework': ['Responsibility of Content',\n",
              "  'Compliance with Applicable Export Control Regimes'],\n",
              " 'Competitive_Behavior': ['Corporate Governance', 'Market Opportunities'],\n",
              " 'Employee_Health_And_Safety': ['Occupational Health & Safety',\n",
              "  'Health Outcome Contribution'],\n",
              " 'Access_And_Affordability': ['Access to Healthcare'],\n",
              " 'Business_Ethics': ['Business Ethics'],\n",
              " 'Ecological_Impacts': ['Biodiversity', 'Sustainable Agricultural Practices'],\n",
              " 'Waste_And_Hazardous_Materials_Management': ['Food Loss & Waste'],\n",
              " 'Water_And_Wastewater_Management': ['Water Related Risks']}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "labels_to_criteria = {}\n",
        "manual_mapping = []\n",
        "\n",
        "# Criteria_Topics is a concatenated list of criteria topics from the industries that we are analyzing\n",
        "with open(\"../final_summary/Scrapers/criteria_topics.txt\", \"r\") as f:\n",
        "    criteria_topics = eval(f.read())\n",
        "\n",
        "for topic in criteria_topics:\n",
        "    inputs = tokenizer(topic, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = outputs.logits.softmax(dim=1)\n",
        "    top_probs, top_labels = torch.topk(probs, k=1)\n",
        "    label = model.config.id2label[top_labels[0][0].item()]\n",
        "    prob = top_probs[0][0].item()\n",
        "\n",
        "    if label not in labels_to_criteria:\n",
        "        labels_to_criteria[label] = []\n",
        "    labels_to_criteria[label].append(topic)\n",
        "\n",
        "# KEY: ESG-BERT's ESG_Labels\n",
        "# Value: List of S&P Global ESG Criteria Topics\n",
        "labels_to_criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSWBxYAdbzZ4"
      },
      "source": [
        "For those ESG_labels that are not mapped to any ESG criteria topics, we would map them manually based on relevancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rJ9cEQA2bzZ4"
      },
      "outputs": [],
      "source": [
        "labels_to_criteria = {\n",
        "    'Physical_Impacts_Of_Climate_Change':['Climate Strategy'],\n",
        "    'Board Composition': ['Women On The Board'],\n",
        "    'Economic Performance': ['Total Assets', 'Net Profit'],\n",
        "    'Business_Model_Resilience': ['Human Capital Development', 'Innovation Management'],\n",
        "    'Human_Rights_And_Community_Relations': ['Human Rights', 'Environmental Policy & Management Systems', 'Social Impacts on Communities', 'Stakeholder Engagement','Employees Gender & Age Diversity'],\n",
        "    'Data_Security': ['Information Security Cybersecurity & System Availability', 'Network Reliability'],\n",
        "    'Energy_Management': ['Operational Eco-Efficiency', 'Low Carbon Strategy', 'Energy Mix', 'Electricity Generation', 'Fuel Efficiency', 'Water Related Risks'],\n",
        "    'Product_Design_And_Lifecycle_Management': ['Product Stewardship', 'Packaging', 'Sustainable Marketing & Brand Perception', 'Sustainable Finance', 'Circular Fashion'],\n",
        "    'Supply_Chain_Management': ['Supply Chain Management'],\n",
        "    'Employee_Engagement_Inclusion_And_Diversity': ['Talent Attraction & Retention', 'Financial Inclusion'],\n",
        "    'Labor_Practices': ['Labor Practice Indicators','Average Training Hours Per Employee'],\n",
        "    'Systemic_Risk_Management': ['Risk & Crisis Management', 'Decarbonization Strategy'],\n",
        "    'Product_Quality_And_Safety': ['Product Quality & Recall Management'],\n",
        "    'Management_Of_Legal_And_Regulatory_Framework': ['Responsibility of Content', 'Compliance with Applicable Export Control Regimes'],\n",
        "    'Competitive_Behavior': ['Corporate Governance', 'Market Opportunities'],\n",
        "    'Employee_Health_And_Safety': ['Occupational Health & Safety', 'Health Outcome Contribution'],\n",
        "    'Access_And_Affordability': ['Access to Healthcare'],\n",
        "    'Business_Ethics': ['Business Ethics'],\n",
        "    'Ecological_Impacts': ['Biodiversity', 'Sustainable Agricultural Practices'],\n",
        "    'Waste_And_Hazardous_Materials_Management': ['Food Loss & Waste', 'Waste Generation'],\n",
        "    'Water_And_Wastewater_Management': ['Water Related Risks'],\n",
        "    'ESG_Certificates': ['List of ESG Certifications'],\n",
        "    \"Air_Quality\": ['Low Carbon Strategy'], # manual mapping\n",
        "    \"Critical_Incident_Risk_Management\": ['Risk & Crisis Management'], # manual mapping\n",
        "    \"Customer_Privacy\": ['Information Security Cybersecurity & System Availability'], # manual mapping\n",
        "    \"Customer_Welfare\": ['Social Impacts on Communities', 'Human Rights', 'Stakeholder Engagement'], # manual mapping\n",
        "    \"Director_Removal\": ['Business Ethics'], # manual mapping\n",
        "    \"GHG_Emissions\": ['Operational Eco-Efficiency', 'Green House Gas Emissions', 'Decarbonization Strategy'], # manual mapping\n",
        "    \"Selling_Practices_And_Product_Labeling\": ['Business Ethics', 'Product Stewardship', 'Packaging', 'Sustainable Marketing & Brand Perception'], # manual mapping\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SunX1V8ebzZ4"
      },
      "source": [
        "### Step 2: Preparing all the mappings collected from webscrapping\n",
        "\n",
        "Import Industry to Criteria Topics Mapping as `industry_criteria_mapping`\n",
        "- Key: Industry\n",
        "- Value: List of most relevant criteria topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXZu6zIqbzZ5",
        "outputId": "3db95074-c76e-49f2-b85a-3adcc5fa43cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Industry: New Energy': ['Climate Strategy',\n",
              "  'Human Capital Development',\n",
              "  'Human Rights',\n",
              "  'Operational Eco-Efficiency',\n",
              "  'Innovation Management',\n",
              "  'Environmental Policy & Management Systems',\n",
              "  'Women On The Board',\n",
              "  'Supply Chain Management',\n",
              "  'Water Related Risks',\n",
              "  'Low Carbon Strategy',\n",
              "  'Corporate Governance',\n",
              "  'Business Ethics',\n",
              "  'Occupational Health & Safety',\n",
              "  'Labor Practice Indicators',\n",
              "  'Waste Generation',\n",
              "  'Green House Gas Emissions',\n",
              "  'Employees Gender & Age Diversity',\n",
              "  'Average Training Hours Per Employee',\n",
              "  'List of ESG Certifications',\n",
              "  'Economic Performance',\n",
              "  'Total Assets',\n",
              "  'Net Profit']}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "industry_criteria_df = pd.read_csv(\"../final_summary/Scrapers/Industry Criteria Topics.csv\").transpose()\n",
        "industry_criteria_mapping = {}\n",
        "\n",
        "for industry, topics in industry_criteria_df.iterrows():\n",
        "    if industry not in industry_criteria_mapping:\n",
        "        industry_criteria_mapping[industry] = []\n",
        "    topics = topics.dropna()\n",
        "    industry_criteria_mapping[industry].extend(topics.to_list())\n",
        "industry_criteria_mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS6hKC2zbzZ5"
      },
      "source": [
        "Import the company to industry mappings as `company_industry_mapping` dictionary\n",
        "- key: TICKER\n",
        "- Value: Industry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0uNctCbzZ5"
      },
      "source": [
        "### Step 3: Run report into ESG-BERT model to classify each sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "lmAY6uAObzZ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def run_model(input_file, model):\n",
        "    counter = 1\n",
        "    max_seq_length = tokenizer.model_max_length\n",
        "    # with open(input_file, \"r\") as f:\n",
        "    input_df = pd.read_csv(input_file)\n",
        "    output = {}\n",
        "    for line in input_df['sentences']:\n",
        "        if len(line) <= max_seq_length:\n",
        "            output['Line ' + str(counter)] = {}\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\")\n",
        "            outputs = model(**inputs)\n",
        "            probs = outputs.logits.softmax(dim=1)\n",
        "\n",
        "            # Extract the top 3 probabilities and labels\n",
        "            top_probs, top_labels = torch.topk(probs, k=3)\n",
        "            # store output\n",
        "            output['Line ' + str(counter)]['Sentence'] = line\n",
        "            for i in range(3):\n",
        "                label = model.config.id2label[top_labels[0][i].item()]\n",
        "                prob = top_probs[0][i].item()\n",
        "                output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
        "            counter += 1\n",
        "        else:\n",
        "            # split input text into chunks\n",
        "            text_chunks = []\n",
        "            for i in range(math.ceil(len(line)/max_seq_length)):\n",
        "                start = i * max_seq_length\n",
        "                end = min((i+1)*max_seq_length, len(line))\n",
        "                text_chunks.append(line[start:end])\n",
        "            for chunk in text_chunks:\n",
        "                output['Line ' + str(counter)] = {}\n",
        "                inputs = tokenizer(chunk, return_tensors=\"pt\", padding= True, truncation=True, max_length=max_seq_length)\n",
        "                outputs = model(**inputs)\n",
        "                probs = outputs.logits.softmax(dim=1)\n",
        "                top_probs, top_labels = torch.topk(probs, k=3)\n",
        "\n",
        "                output['Line ' + str(counter)]['Sentence'] = line\n",
        "                for i in range(3):\n",
        "                    label = model.config.id2label[top_labels[0][i].item()]\n",
        "                    prob = top_probs[0][i].item()\n",
        "                    output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
        "                counter += 1\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "905CgNgdbzZ6"
      },
      "source": [
        "### Step 4: Mapping output labels to our criteria topics\n",
        "- We will map the output labels generated by ESG-BERT with the mapping, `mapped_to_criteria`\n",
        "- We also have decided to classify sentences whose label with the highest probability is less than 0.50 as `Non-ESG`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dz25SvvqbzZ6"
      },
      "outputs": [],
      "source": [
        "''' [How it works]\n",
        "    1. Get the list of most relevant criteria topics for the company based on its industry\n",
        "    2. Based on the ESG_label with the highest probability, we get the list of potential criteria topics that can be mapped to the target ESG_label\n",
        "    3. We check the list of potential criteria topics using the list of most relevant criteria topics\n",
        "    4. If it exists, we just map the label to that criteria topic.\n",
        "'''\n",
        "def process_output(result, industry_criteria_mapping):\n",
        "    # 将行业硬编码为“新能源”\n",
        "    industry = \"Industry: New Energy\"\n",
        "\n",
        "    # 初始化 DataFrame\n",
        "    df = pd.DataFrame.from_dict(result, orient='index')\n",
        "\n",
        "    # 获取“新能源”行业的相关 ESG 主题列表\n",
        "    industry_criteria_topics = industry_criteria_mapping[industry]\n",
        "\n",
        "    def mapperFunction(row, industry_criteria_topics):\n",
        "        value = row[1]\n",
        "        if value < 0.5:\n",
        "            return (\"NON-ESG\", value)\n",
        "        else:\n",
        "            # 获取当前 ESG 标签的潜在映射主题\n",
        "            mapped_criteria_topics = labels_to_criteria[row[0]]\n",
        "            result = []\n",
        "            # 检查是否符合“新能源”行业标准主题\n",
        "            for topic in mapped_criteria_topics:\n",
        "                if topic in industry_criteria_topics:\n",
        "                    result.append(topic)\n",
        "            return (result, value)\n",
        "    df['Mapped Criteria Topic 1'] = df['ESG BERT Topic 1'].apply(lambda x: mapperFunction(x,industry_criteria_topics))\n",
        "    df['Mapped Criteria Topic 2'] = df['ESG BERT Topic 2'].apply(lambda x: mapperFunction(x,industry_criteria_topics))\n",
        "    df['Mapped Criteria Topic 3'] = df['ESG BERT Topic 3'].apply(lambda x: mapperFunction(x,industry_criteria_topics))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXYF5LidbzZ6"
      },
      "source": [
        "### Step 5: Export as CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "drs-5Z40bzZ7"
      },
      "outputs": [],
      "source": [
        "def export_output_to_csv(df, output_filename):\n",
        "    df.to_csv(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgeKIZGUbzZ7"
      },
      "source": [
        "### Step 6: Run all reports into the ESG-BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHvYR9m5bzZ7"
      },
      "source": [
        "### NOTE: This will take about 2 hours to classify all 50 ESG reports\n",
        "- For sample output, please run the commented code instead and comment out this chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1Fv-RLSrbzZ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "Note: This will take about 2 hours to classify all 25 ESG reports.\n",
        "\n",
        "For a sample output please run the code chunk below\n",
        "'''\n",
        "input_file = output_filename\n",
        "output_file = \"../final_summary/classified_sentences/\"+input_filename.split(\"/\")[-1]\n",
        "\n",
        "output_result = run_model(input_file, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = process_output(output_result, industry_criteria_mapping)\n",
        "export_output_to_csv(output_df, output_file)\n",
        "print(f\"Exported to {output_file}\")\n",
        "\n",
        "######## SAMPLE OUTPUT RUN THIS ########\n",
        "# filename = \"AMZN_2021.csv\"\n",
        "# ticker = filename.split(\"_\")[0]\n",
        "# industry = company_industry_mapping[ticker]\n",
        "# input_file = \"pdf_text\" + \"/\" + filename\n",
        "# ouptut_file = \"output/classified_sentences/\" + filename.replace(\".csv\", \"_results.csv\")\n",
        "# output_result = run_model(input_file, model)\n",
        "# output_df = process_output(output_result, industry_criteria_mapping, industry)\n",
        "# export_output_to_csv(output_df, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDkUIouacxv",
        "outputId": "d37d6f62-7744-4626-ebca-095b9cb8fc95"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported to ../BT4222_Group21/output/classified_sentences/2024_released_CGN_ESG_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nawq3q88P2Iw",
        "outputId": "a1324fc9-40cb-474b-c3cd-20398c58a06b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import re"
      ],
      "metadata": {
        "id": "IfZf4yiwP2Lr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "topics_by_company = {}\n",
        "reports = {}\n",
        "df = pd.read_csv(output_file)\n",
        "ticker = output_file.split('/')[-1].split('_')[0]\n",
        "reports[ticker] = df\n",
        "\n",
        "for company, data in reports.items():\n",
        "    topics_by_company[company] = {}\n",
        "    for index, row in data.iterrows():\n",
        "        mapped_criteria_topic_1 = literal_eval(row['Mapped Criteria Topic 1'])\n",
        "        mapped_criteria_topic_2 = literal_eval(row['Mapped Criteria Topic 2'])\n",
        "        mapped_criteria_topic_3 = literal_eval(row['Mapped Criteria Topic 3'])\n",
        "        sentence = row['Sentence']\n",
        "        if mapped_criteria_topic_1[0] != 'NON-ESG':\n",
        "            if mapped_criteria_topic_1[0] != []:\n",
        "                for i in  mapped_criteria_topic_1[0]:\n",
        "                    if i not in topics_by_company[company]:\n",
        "                        topics_by_company[company][i] = {}\n",
        "                    topics_by_company[company][i][sentence] = mapped_criteria_topic_1[1]\n",
        "            else:\n",
        "                if mapped_criteria_topic_2[0] != 'NON-ESG':\n",
        "                    if mapped_criteria_topic_2[0] != []:\n",
        "                        for i in  mapped_criteria_topic_2[0]:\n",
        "                            if i not in topics_by_company[company]:\n",
        "                                topics_by_company[company][i] = {}\n",
        "                            topics_by_company[company][i][sentence] = mapped_criteria_topic_2[1]\n",
        "                    else:\n",
        "                        if mapped_criteria_topic_3[0] != 'NON-ESG':\n",
        "                            if mapped_criteria_topic_3[0] != []:\n",
        "                                for i in  mapped_criteria_topic_3[0]:\n",
        "                                    if i not in topics_by_company[company]:\n",
        "                                        topics_by_company[company][i] = {}\n",
        "                                    topics_by_company[company][i][sentence] = mapped_criteria_topic_3[1]"
      ],
      "metadata": {
        "id": "yG3y8XvdUyzX"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort sentences by topic according to probability\n",
        "for company, data in topics_by_company.items():\n",
        "    for topic, sentence_prob in data.items():\n",
        "        sorted_sentence_prob = dict(sorted(sentence_prob.items(), key = lambda x: x[1], reverse=True))\n",
        "        topics_by_company[company][topic] = sorted_sentence_prob"
      ],
      "metadata": {
        "id": "zS37jGiNUy12"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_topic_sentences = {}\n",
        "for company, data in topics_by_company.items():\n",
        "    company_topic_sentences[company] = {}\n",
        "    for topic, sentences in data.items():\n",
        "        if topic not in company_topic_sentences[company]:\n",
        "            company_topic_sentences[company][topic] = []\n",
        "        for sentence, prob in sentences.items():\n",
        "            company_topic_sentences[company][topic].append(sentence)"
      ],
      "metadata": {
        "id": "HPzpQYBdUy4N"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Helper function to split the text into segments\n",
        "def split_in_segments(text):\n",
        "    tokens = 0\n",
        "    mystring = list()\n",
        "    segments = []\n",
        "    text = re.sub(r'(?<=\\w)(\\.)', r' \\1', text)\n",
        "    for sent in sent_tokenize(text):\n",
        "        newtokens = len(sent.split())\n",
        "        if tokens + newtokens > 500:\n",
        "            segments.append(\" \".join(mystring))\n",
        "            mystring = []\n",
        "            mystring.append(str(sent).strip())\n",
        "            tokens = newtokens\n",
        "        elif newtokens > 500:\n",
        "            segments.extend([str(sent)[i:i+500] for i in range(0, len(str(sent)), 500)])\n",
        "        else:\n",
        "            tokens += newtokens\n",
        "            mystring.append(str(sent).strip())\n",
        "\n",
        "    if mystring:\n",
        "        segments.append(\" \".join(mystring))\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Helper Function to summarize text based on input text\n",
        "def summarize_text(input_text):\n",
        "    segments = split_in_segments(input_text)\n",
        "    summaries = []\n",
        "    for seg in segments:\n",
        "        summary = summarizer(seg, truncation = True, max_length=100, min_length=30, do_sample=False)\n",
        "        summaries.extend(summary)\n",
        "    return summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-r6jUL4VIf1",
        "outputId": "61c4ef36-b8f2-439f-9b3b-4ce87f024a5c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "company_summary_sentences = {}\n",
        "\n",
        "for company, data in company_topic_sentences.items():\n",
        "    print(f\"Summarizing {company}\")\n",
        "    output = {}\n",
        "\n",
        "    for topic, sentences in data.items():\n",
        "        print(f\"### Topic: {topic} ###\")\n",
        "\n",
        "        input_sentences = \" \".join(sentences[:20]) # Top 20 sentences\n",
        "        reference_summary = sentences[:40] # reference summary don't change\n",
        "        summary_list = summarize_text(input_sentences)\n",
        "        combined_summary = summary_list[0]['summary_text']\n",
        "        for summary in summary_list[1:]:\n",
        "            combined_summary += summary['summary_text']\n",
        "        output[topic] = (combined_summary, \" \".join(reference_summary))\n",
        "    if company not in company_summary_sentences:\n",
        "        company_summary_sentences[company] = {}\n",
        "    company_summary_sentences[company] = output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43bBEVc_VIiM",
        "outputId": "2fd2c44d-2634-4168-ecc9-16d44a4a0c3f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizing 2024\n",
            "### Topic: Human Capital Development ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 46. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Topic: Innovation Management ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 46. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Topic: Occupational Health & Safety ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 88. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Topic: Climate Strategy ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 43. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Topic: Human Rights ###\n",
            "### Topic: Environmental Policy & Management Systems ###\n",
            "### Topic: Employees Gender & Age Diversity ###\n",
            "### Topic: Operational Eco-Efficiency ###\n",
            "### Topic: Low Carbon Strategy ###\n",
            "### Topic: Water Related Risks ###\n",
            "### Topic: Business Ethics ###\n",
            "### Topic: Corporate Governance ###\n",
            "### Topic: Green House Gas Emissions ###\n",
            "### Topic: Supply Chain Management ###\n",
            "### Topic: Waste Generation ###\n",
            "### Topic: Labor Practice Indicators ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 73. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Topic: Average Training Hours Per Employee ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 73. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame.from_dict(output, orient='index')\n",
        "output_df = output_df.rename_axis(\"topic\").reset_index()\n",
        "output_df.rename(columns={0: \"combined_summary\", 1: \"reference_summary\"}, inplace=True)\n",
        "output_df.to_csv(f\"../final_summary/Generated Summaries/{company}_top20_summaries.csv\")"
      ],
      "metadata": {
        "id": "dYghqOkgIjSf"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to compute ROUGE-N scores from Huggingface's evaluate library\n",
        "import evaluate\n",
        "def evaluateRouge(output):\n",
        "    output_results = {}\n",
        "    rouge = evaluate.load('rouge')\n",
        "    for idx, row in output.iterrows():\n",
        "        topic = row[0]\n",
        "        generated = [row[1]]\n",
        "        reference = [row[2]]\n",
        "        results = rouge.compute(predictions=generated, references = reference)\n",
        "        output_results[topic] = results\n",
        "    return output_results"
      ],
      "metadata": {
        "id": "dGx6adRbVIkB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to calculate the average ROUGE-N score\n",
        "def averageEvaluation(results):\n",
        "    output_dict = {\n",
        "        'rouge1': 0,\n",
        "        'rouge2': 0,\n",
        "        'rougeL': 0,\n",
        "        'rougeLsum': 0\n",
        "    }\n",
        "    for topic, rougeData in results.items():\n",
        "        output_dict['rouge1'] = sum(val['rouge1'] for val in results.values())/len(results)\n",
        "        output_dict['rouge2'] = sum(val['rouge2'] for val in results.values())/len(results)\n",
        "        output_dict['rougeL'] = sum(val['rougeL'] for val in results.values())/len(results)\n",
        "        output_dict['rougeLsum'] = sum(val['rougeLsum'] for val in results.values())/len(results)\n",
        "    return output_dict"
      ],
      "metadata": {
        "id": "5MUUO6uVVImg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxWTBLqjorm",
        "outputId": "1d0298c1-000c-443e-e896-fffadf6ee0b7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each company, compute average ROUGE-N scores across all generated summaries\n",
        "import os\n",
        "generated_summaries_path = \"../final_summary/Generated Summaries/\"\n",
        "\n",
        "evaluation_results = {}\n",
        "\n",
        "for filename in os.listdir(generated_summaries_path):\n",
        "    summaries = pd.read_csv(generated_summaries_path + filename)\n",
        "    summaries_result = evaluateRouge(summaries)\n",
        "    company = filename.split(\"_\")[0]\n",
        "    input_type = filename.split(\"_\")[1]\n",
        "    if input_type not in evaluation_results:\n",
        "        evaluation_results[input_type] = {}\n",
        "    evaluation_results[input_type][company] = averageEvaluation(summaries_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlkmcA_eVbqS",
        "outputId": "075e5eb7-61c7-4835-92a8-558b9479ca85"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-9d74cd3c5669>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  topic = row[0]\n",
            "<ipython-input-66-9d74cd3c5669>:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  generated = [row[1]]\n",
            "<ipython-input-66-9d74cd3c5669>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  reference = [row[2]]\n",
            "<ipython-input-66-9d74cd3c5669>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  topic = row[0]\n",
            "<ipython-input-66-9d74cd3c5669>:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  generated = [row[1]]\n",
            "<ipython-input-66-9d74cd3c5669>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  reference = [row[2]]\n",
            "<ipython-input-66-9d74cd3c5669>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  topic = row[0]\n",
            "<ipython-input-66-9d74cd3c5669>:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  generated = [row[1]]\n",
            "<ipython-input-66-9d74cd3c5669>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  reference = [row[2]]\n",
            "<ipython-input-66-9d74cd3c5669>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  topic = row[0]\n",
            "<ipython-input-66-9d74cd3c5669>:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  generated = [row[1]]\n",
            "<ipython-input-66-9d74cd3c5669>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  reference = [row[2]]\n",
            "<ipython-input-66-9d74cd3c5669>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  topic = row[0]\n",
            "<ipython-input-66-9d74cd3c5669>:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  generated = [row[1]]\n",
            "<ipython-input-66-9d74cd3c5669>:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  reference = [row[2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save evaluation data as pickle file to reopen for review\n",
        "import pickle\n",
        "\n",
        "save_file = True # Set as true if you want to save the evaluation_results dictionary as pickle file\n",
        "\n",
        "if save_file: # save evaluation results as pickle file\n",
        "    file_to_save = open('Evaluation_Result', 'ab')\n",
        "    pickle.dump(evaluation_results, file_to_save)\n",
        "    file_to_save.close()\n",
        "else: # Set as false to open the file\n",
        "    saved_file = open('Evaluation_Result', 'rb')\n",
        "    evaluation_results = pickle.load(saved_file)"
      ],
      "metadata": {
        "id": "w3T3BmzZVbsy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Average ROUGE-N scores across types of inputs (Top20/Top30/Random20/Random30)\n",
        "show_evaluation = {}\n",
        "for k,v in evaluation_results.items():\n",
        "    show_evaluation[k] = {\n",
        "        'rouge1': 0,\n",
        "        'rouge2': 0,\n",
        "        'rougeL': 0,\n",
        "        'rougeLsum': 0\n",
        "    }\n",
        "\n",
        "    show_evaluation[k]['rouge1'] = sum(val['rouge1'] for val in v.values())/len(v)\n",
        "    show_evaluation[k]['rouge2'] = sum(val['rouge2'] for val in v.values())/len(v)\n",
        "    show_evaluation[k]['rougeL'] = sum(val['rougeL'] for val in v.values())/len(v)\n",
        "    show_evaluation[k]['rougeLsum'] = sum(val['rougeLsum'] for val in v.values())/len(v)\n",
        "\n",
        "pd.DataFrame.from_dict(show_evaluation, orient='index').sort_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "OCHZ7QHLVbur",
        "outputId": "c0ff38b2-1f56-484f-ad11-6ece5becaa17"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         rouge1    rouge2    rougeL  rougeLsum\n",
              "top15  0.010351  0.002196  0.009916   0.009916\n",
              "top20  0.098327  0.089530  0.092187   0.092187\n",
              "top25  0.008304  0.001392  0.007948   0.007948\n",
              "top30  0.007508  0.001335  0.007178   0.007178"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d26f22d-c7e6-4119-9b24-285bad53a533\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>top15</th>\n",
              "      <td>0.010351</td>\n",
              "      <td>0.002196</td>\n",
              "      <td>0.009916</td>\n",
              "      <td>0.009916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top20</th>\n",
              "      <td>0.098327</td>\n",
              "      <td>0.089530</td>\n",
              "      <td>0.092187</td>\n",
              "      <td>0.092187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top25</th>\n",
              "      <td>0.008304</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.007948</td>\n",
              "      <td>0.007948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top30</th>\n",
              "      <td>0.007508</td>\n",
              "      <td>0.001335</td>\n",
              "      <td>0.007178</td>\n",
              "      <td>0.007178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d26f22d-c7e6-4119-9b24-285bad53a533')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d26f22d-c7e6-4119-9b24-285bad53a533 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d26f22d-c7e6-4119-9b24-285bad53a533');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7df119a2-be7b-4cc1-be12-48e44fab85e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7df119a2-be7b-4cc1-be12-48e44fab85e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7df119a2-be7b-4cc1-be12-48e44fab85e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04481902913801214,\n        \"min\": 0.0075076456470669455,\n        \"max\": 0.09832706174545568,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.09832706174545568,\n          0.0075076456470669455,\n          0.010351440565976568\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043946067240144604,\n        \"min\": 0.0013353485674022828,\n        \"max\": 0.08952957577513712,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.08952957577513712,\n          0.0013353485674022828,\n          0.002195883126969868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04193554185194553,\n        \"min\": 0.00717842754007106,\n        \"max\": 0.09218692165748722,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.09218692165748722,\n          0.00717842754007106,\n          0.009915710718482013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04193554185194553,\n        \"min\": 0.00717842754007106,\n        \"max\": 0.09218692165748722,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.09218692165748722,\n          0.00717842754007106,\n          0.009915710718482013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# 设置 OpenAI API 密钥\n",
        "openai.api_key = 'sk-vzRrOeVbcm0RfRvb7k29Sy13PNAqCdChUvmvaDVs4iT3BlbkFJZcMi-v0cfYyqyTzr9xfM0QIk9Lk_8vPkdbCGaHxKUA'\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# 读取CSV文件\n",
        "csv_file_path = f\"../final_summary/Generated Summaries/{company}_top20_summaries.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 定义用于调用 ChatGPT API 的函数\n",
        "def get_quantitative_summary(text):\n",
        "    # Use client.chat.completions.create with OpenAI object\n",
        "    client = openai.OpenAI(api_key='sk-vzRrOeVbcm0RfRvb7k29Sy13PNAqCdChUvmvaDVs4iT3BlbkFJZcMi-v0cfYyqyTzr9xfM0QIk9Lk_8vPkdbCGaHxKUA',) # Create an OpenAI object\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\", # Use a suitable chat model, like gpt-3.5-turbo\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful ESG expert that summarizes a company's ESG report text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Please summarize the following text in 1-2 sentences containing quantitative explanation if available:\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.3,  # 保持生成内容的稳定性\n",
        "        max_tokens=500,\n",
        "        top_p=1.0,       # 使用完整的采样\n",
        "        frequency_penalty=0,  # 允许适度重复关键信息\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    summary = response.choices[0].message.content # Access the summary text from the response\n",
        "    return summary.strip()\n",
        "\n",
        "# 存储每行处理后的量化摘要\n",
        "summary_sentences = []\n",
        "\n",
        "# 遍历每行，调用 API 生成量化的1-2句总结\n",
        "for index, row in df.iterrows():\n",
        "    topic = row['topic']\n",
        "    combined_summary = row['combined_summary']\n",
        "\n",
        "    # 调用 ChatGPT API 生成量化总结\n",
        "    quantitative_summary = get_quantitative_summary(combined_summary)\n",
        "\n",
        "    # 将量化总结添加到列表中\n",
        "    summary_sentences.append(f\"{topic}:{quantitative_summary}\\n\")\n",
        "\n",
        "# 拼接成完整的公司级摘要\n",
        "final_summary = \" \".join(summary_sentences)\n",
        "\n",
        "# 打印公司级摘要\n",
        "print(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwYPNzn5VbxP",
        "outputId": "52b60f57-0f78-4cba-b2e2-c524649560f9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human Capital Development:The company emphasizes market awareness through business strategy, risk assessment, and transparent communication with stakeholders, including monthly power generation updates and major project disclosures. They are committed to enhancing ESG reporting and partnering with sustainable business allies.\n",
            " Innovation Management:The company emphasizes market awareness through its business strategy, market opportunities, and marketing efforts. They assess risks in alignment with business objectives, strategic focus, and performance-based assessment. The company also provides regular updates on power generation and discloses major project investments to meet market expectations and improve transparency. They commit to enhancing ESG reporting to meet stakeholder expectations and aim to collaborate with partners who share their values and commitment to sustainability.\n",
            " Occupational Health & Safety:CGN New Energy Holdings Co., Ltd. emphasizes occupational health and safety through measures such as risk analysis seminars and internal management policies to prevent employee injuries. The company also focuses on being a good neighbor, friend, and partner to contribute to society, with internal audits conducted to assess the effectiveness of their health and safety management system.\n",
            " Climate Strategy:CGN New Energy is proactive in addressing climate change risks and opportunities, with no major climate risks but medium to low-level risks identified. The company integrates climate-related issues into operational risk management, releases environmental management plans annually, and aligns its strategy with national low-carbon goals. Additionally, the company has not faced significant penalties for violating laws or regulations during the reporting period.\n",
            " Human Rights:The company focuses on renewable energy opportunities, energy efficiency, and environmental impact assessments to address climate change. It also emphasizes employee rights and supply chain security in its social category indicators. The management members' variable salary is between 50% and 60%, and board members' remuneration is set according to relevant standards. The company actively fulfills its social responsibility as a Central Enterprise, working with partners to overcome challenges and caring for employees.\n",
            " Environmental Policy & Management Systems:The company focuses on renewable energy opportunities, project-related protection of the environment, energy efficiency, and greenhouse gas emissions management in its ESG efforts. It publishes annual environmental management plans, prioritizes energy-efficient equipment purchases, and has a variable salary structure for management members. The company's business mainly involves electricity generation, and it actively fulfills its social responsibility as a Central Enterprise while emphasizing governance systems, environmental protection, employee relations, and community contributions.\n",
            " Employees Gender & Age Diversity:The company focuses on renewable energy opportunities, project-related protection of the environment, energy efficiency, solid waste disposal, and greenhouse gas emissions in its ESG report. It also highlights its environmental management plans, energy-efficient equipment procurement practices, and social responsibility efforts, including employee relations and community contributions. The company's management members' variable salary ranges from 50% to 60%, and board member remuneration is set according to relevant standards.\n",
            " Operational Eco-Efficiency:During the reporting period, CGN New Energy focused on increasing energy efficiency and promoting the development of green energy across various projects, resulting in a year-on-year decrease of 6.4% in energy consumed per MWh of electricity generated, reaching 0.92 MWh. The company achieved 100% green consumption of office electricity and developed a specialized plan for green electricity consumption, including an analysis of electricity consumption patterns across all units.\n",
            " Low Carbon Strategy:CGN New Energy has successfully reduced its total energy consumption by 7.0% year-on-year to 17,601,035.88 MWh, with an energy consumption per MWh of electricity generated at 0.92 MWh. The company is increasing its investment in renewable energy to promote the development of green energy and aims to provide high-quality green energy for power users in the future.\n",
            " Water Related Risks:CGN New Energy is committed to energy efficiency and increasing investment in renewable energy. They aim to enhance safety, refine production management, and respond to market reforms. During the reporting period, the company consumed a total of 6,296,438,986.82 m3 of water, with surface water accounting for the majority at 6,294,357,759.54 m3.\n",
            " Business Ethics:CGN New Energy has a strong commitment to anti-corruption practices, with no identified corruption risks or violations during the reporting period. The company has established a Whistleblowing Policy System to encourage employees to report misconduct, fraud, or corruption confidentially. Additionally, the company focuses on environmental management, with annual publication of environmental management plans and investigation and treatment of hidden environmental risks. The company also emphasizes integrity and transparency in governance, with a focus on cultivating a culture of ethics and continually improving its internal governance system.\n",
            " Corporate Governance:The company prioritizes energy-efficient equipment purchases and conducts annual environmental management plans to address hidden environmental risks. They have not encountered negative incidents related to their products or services, and disclose financial information annually while emphasizing their commitment to clean energy development. Additionally, they signed a talent training agreement and issued intellectual property management measures.\n",
            " Green House Gas Emissions:During the reporting period, CGN New Energy Holdings Co. focused on reducing greenhouse gas emissions by improving energy efficiency, increasing investment in clean and renewable energy projects, and complying with air and greenhouse gas emission regulations. The company has not participated in trading energy use rights, water rights, or emission rights, and aims to disclose GHG emissions in Scope 3.\n",
            " Supply Chain Management:The company primarily employs third-party contractors and has conducted an ESG risk assessment to identify major risks. They prioritize energy-efficient equipment purchases, have not encountered negative incidents related to their products/services, and have established internal policies to protect customer privacy and mitigate environmental and social risks in the supply chain. The management members' variable salary is between 50% and 60%, assessed by the Board, and the remuneration of board members is set according to relevant standards.\n",
            " Waste Generation:The company has not violated any laws related to emissions, waste generation, and noise. They have not separately calculated non-fossil energy consumption for listed platform projects. The company does not trade energy, water, or emission rights and discloses GHG emissions in Scope 3. In terms of waste management, the company produces various wastes in power production and has mechanisms in place for their disposal. In terms of energy and water consumption, the company consumed 1,521,886.28 MWh of energy and 20,904,013.68 m3 of water in 2023.\n",
            " Labor Practice Indicators:The Group upholds strict policies against child labor and forced labor, with 100% of employees covered by collective bargaining agreements. In 2023, the company provided reasonable salaries, benefits, and leave entitlements to all full-time employees, while maintaining compliance with relevant laws and regulations. Trade unions within the Group and its managed companies conducted 1,901 association activities involving over 18,500 person-times in 2023.\n",
            " Average Training Hours Per Employee:The Group has a strong commitment to labor rights, with 100% of employees covered by collective bargaining agreements and no violations of laws related to compensation, dismissal, recruitment, working hours, rest periods, and equal opportunities reported. Additionally, in 2023, trade unions within the Group conducted 1,901 association activities involving more than 18,500 individuals.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Topic"
      ],
      "metadata": {
        "id": "qxoEjNFvMOBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber PyPDF2\n",
        "! pip install transformers\n",
        "import datetime\n",
        "!pip install sentencepiece accelerate\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "QnHR3gG2NMZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2DlRCd-NOnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tua5KMMGNOpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oae94F7nNOsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0c4gX9GNOuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_V__WTPNOwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgscFKkDNOyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}