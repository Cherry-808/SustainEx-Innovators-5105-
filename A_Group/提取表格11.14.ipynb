{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a562c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import os\n",
    "import threading\n",
    "import pdfplumber\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "UPLOAD_FOLDER = './uploads'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "# 确保上传文件夹存在\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "# 文件上传接口\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'message': 'No file part in the request'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    if file.filename == '':\n",
    "        return jsonify({'message': 'No file selected for uploading'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        file.save(file_path)\n",
    "        \n",
    "        # 处理CSV文件或PDF文件\n",
    "        if file.filename.lower().endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                # 在这里对数据进行一些基本分析（例如显示数据的列名和行数）\n",
    "                analysis_result = {\n",
    "                    'columns': df.columns.tolist(),\n",
    "                    'row_count': len(df),\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return jsonify({'message': f'Error processing file: {str(e)}'}), 500\n",
    "            \n",
    "            return jsonify({'message': 'File uploaded successfully!', 'analysis_result': analysis_result}), 200\n",
    "        elif file.filename.lower().endswith('.pdf'):\n",
    "            try:\n",
    "                # 使用 pdfplumber 读取 PDF 文件内容\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    text = \"\"\n",
    "                    for page in pdf.pages:\n",
    "                        text += page.extract_text()\n",
    "                \n",
    "                # 返回前几行的内容作为示例\n",
    "                preview_text = text[:500]  # 取前500个字符作为预览\n",
    "                return jsonify({'message': 'PDF file uploaded successfully!', 'preview': preview_text}), 200\n",
    "            except Exception as e:\n",
    "                return jsonify({'message': f'Error processing PDF file: {str(e)}'}), 500\n",
    "        else:\n",
    "            return jsonify({'message': 'Invalid file type.'}), 400\n",
    "    else:\n",
    "        return jsonify({'message': 'Invalid file type. Please upload a CSV or PDF file.'}), 400\n",
    "\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ['csv', 'pdf']\n",
    "\n",
    "# 启动Flask应用程序的线程\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=lambda: app.run(host='127.0.0.1', port=5000, debug=False)).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5cf203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 5000 is in use.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "def check_port_in_use(port):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        return s.connect_ex(('127.0.0.1', port)) == 0\n",
    "\n",
    "port = 5000\n",
    "if check_port_in_use(port):\n",
    "    print(f\"Port {port} is in use.\")\n",
    "else:\n",
    "    print(f\"Port {port} is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "current_path = os.getcwd()\n",
    "config.read(os.path.join(current_path, 'config.ini'))\n",
    "\n",
    "# 设置输入和输出路径\n",
    "input_path = config['DEFAULT'].get('Input-Path', os.path.join(current_path, 'input'))\n",
    "output_path = config['DEFAULT'].get('Output-Path', os.path.join(current_path, 'output'))\n",
    "debug = config['DEFAULT'].getboolean('Debug', False)\n",
    "\n",
    "# 检查并创建输入路径\n",
    "if not os.path.exists(input_path):\n",
    "    os.makedirs(input_path)  # 自动创建路径\n",
    "    print(f\"Created input directory: {input_path}\")\n",
    "\n",
    "# 检查并创建输出路径\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)  # 自动创建路径\n",
    "    print(f\"Created output directory: {output_path}\")\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "current_path = os.getcwd()\n",
    "config.read(os.path.join(current_path, 'config.ini'))\n",
    "\n",
    "input_path = config['DEFAULT']['Input-Path']\n",
    "output_path = config['DEFAULT']['Output-Path']\n",
    "debug = config['DEFAULT'].getboolean('Debug')\n",
    "\n",
    "# 确保输入和输出路径存在\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"Input path does not exist: {input_path}\")\n",
    "    raise FileNotFoundError(f\"Input path does not exist: {input_path}\")\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Created output directory: {output_path}\")\n",
    "\n",
    "# 定义提取图片的函数\n",
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open PDF file {pdf_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        if debug:\n",
    "            print(f\"Created folder: {output_folder}\")\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        if not image_list:\n",
    "            if debug:\n",
    "                print(f\"No images found on page {page_num + 1}.\")\n",
    "            continue\n",
    "\n",
    "        for image_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            try:\n",
    "                base_image = pdf_document.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                # 使用 page_num 和 image_index 确保文件名唯一\n",
    "                image_name = f\"image_{page_num + 1}_{image_index + 1}.{image_ext}\"\n",
    "                image_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "                with open(image_path, \"wb\") as image_file:\n",
    "                    image_file.write(image_bytes)\n",
    "                print(f\"Saved image: {image_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to extract image {image_index + 1} on page {page_num + 1}: {e}\")\n",
    "\n",
    "# 定义渲染页面为图像的函数\n",
    "def render_pdf_page_as_image(pdf_path, output_folder, zoom=2):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open PDF file {pdf_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        if debug:\n",
    "            print(f\"Created folder: {output_folder}\")\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        mat = fitz.Matrix(zoom, zoom)  # 放大倍率\n",
    "        try:\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            image_name = f\"page_{page_num + 1}.png\"\n",
    "            image_path = os.path.join(output_folder, image_name)\n",
    "            pix.save(image_path)\n",
    "            print(f\"Rendered page {page_num + 1} as image: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to render page {page_num + 1}: {e}\")\n",
    "\n",
    "# 获取 input_path 目录中的所有 PDF 文件\n",
    "pdf_files = [f for f in os.listdir(input_path) if f.lower().endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found in the input directory.\")\n",
    "else:\n",
    "    print(f\"Found {len(pdf_files)} PDF file(s) in the input directory.\")\n",
    "\n",
    "# 对每个 PDF 文件进行图片提取和页面渲染\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(input_path, pdf_file)\n",
    "\n",
    "    # 为每个 PDF 创建单独的文件夹\n",
    "    pdf_base_name = os.path.splitext(pdf_file)[0]\n",
    "    images_output_folder = os.path.join(output_path, pdf_base_name, \"extracted_images\")\n",
    "    rendered_pages_folder = os.path.join(output_path, pdf_base_name, \"rendered_pages\")\n",
    "\n",
    "    print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "\n",
    "    # 提取图片\n",
    "    print(\"Extracting images...\")\n",
    "    extract_images_from_pdf(pdf_path, images_output_folder)\n",
    "\n",
    "    # 渲染页面为图像\n",
    "    print(\"Rendering pages as images...\")\n",
    "    render_pdf_page_as_image(pdf_path, rendered_pages_folder, zoom=2)\n",
    "\n",
    "    print(f\"Completed processing {pdf_file}\\n\")\n",
    "\n",
    "print(\"All PDF files have been processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63324b07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have already set up your OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-OkrSl6y7ucYQ7VaO20E7F059Ae044b4f8381A08606C54c7c\",\n",
    "    base_url=\"https://www.gptapi.us/v1\",\n",
    ")\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(model_name, exist_ok=True)\n",
    "output_path = f\"{model_name}/processed_data.csv\"\n",
    "\n",
    "# Path to your extracted images\n",
    "extracted_images_dir = r'.\\output\\ST-Engineering-Sustainability-Report2020\\rendered_pages'\n",
    "\n",
    "# Function to encode images\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# System prompt and user instructions\n",
    "system_prompt = 'You are an expert in data extraction, specializing in extracting tabular data from images.'\n",
    "text_content = '''\n",
    "Extract meaningful data, especially numbers and related textual information, \n",
    "from the image and convert it into a structured \n",
    "JSON format with the following fields: \"Index class\", \"Index prefix\", \"Index name\", \n",
    "\"2019\", \"2020\", \"2021\", \"2022\", and \"2023\". \n",
    "If any field does not exist, set its value to null. \n",
    "Please retain all data in its original format, especially numeric values, and avoid any translation or conversion to other languages. \n",
    "Skip extraction if there is no meaningful data in the image.\n",
    "**Note:** There may be multiple sets of data in this format on a single page. Please extract all relevant information; otherwise, penalties may apply.\n",
    "For example, the JSON structure should look like this: \n",
    "JSON structure\n",
    "\"\"\"\n",
    "{\n",
    "    \"Index class\": \"Environmental\", \n",
    "    \"Index prefix\": \"CO2 emissions at Scope 1 production facilities (t CO2 eq)\", \n",
    "    \"Index name\": \"Thermal generating plants\", \n",
    "    \"2019\": \"7123465\",\n",
    "    \"2020\": \"9123465\",\n",
    "    \"2021\": \"10423465\",\n",
    "    \"2022\": \"10523465\",\n",
    "    \"2023\": \"10623465\"\n",
    "}\n",
    "\"\"\"\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "with open(output_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Update the column headers\n",
    "    writer.writerow([\"Image Name\", \"Index class\", \"Index prefix\", \"Index name\", \"2019\", \"2020\", \"2021\", \"2022\",\"2023\"])  \n",
    "\n",
    "    if os.path.exists(extracted_images_dir):\n",
    "        for i in range(1, len(os.listdir(extracted_images_dir))):\n",
    "            file_name = f'page_{i}.png'\n",
    "            image_path = os.path.join(extracted_images_dir, file_name)\n",
    "            if os.path.isfile(image_path):\n",
    "                base64_image = encode_image(image_path)\n",
    "\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": text_content},\n",
    "                        ],\n",
    "                    },\n",
    "                ]\n",
    "\n",
    "                messages[-1][\"content\"].append(\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                resp = client.chat.completions.create(model=model_name,response_format={\"type\": \"json_object\"},messages=messages, temperature=0.0)\n",
    "                extracted_data = resp.choices[0].message.content\n",
    "                print(f\"Extracted data for {file_name}: {extracted_data}\")\n",
    "\n",
    "            if extracted_data:\n",
    "                try:\n",
    "                    data = json.loads(extracted_data)\n",
    "                    if isinstance(data, list):\n",
    "                        for row in data:\n",
    "                            index_class = row.get('Index class', '')\n",
    "                            index_prefix = row.get('Index prefix', '')\n",
    "                            index_name = row.get('Index name', '')\n",
    "                            value_2019 = row.get('2019', '')\n",
    "                            value_2020 = row.get('2020', '')\n",
    "                            value_2021 = row.get('2021', '')\n",
    "                            value_2022 = row.get('2022', '')\n",
    "                            value_2023 = row.get('2023', '')\n",
    "                            writer.writerow([file_name, index_class, index_prefix, index_name, value_2019, value_2020, value_2021, value_2022, value_2023])\n",
    "                    elif isinstance(data, dict):\n",
    "                        # 如果数据是单个字典\n",
    "                        index_class = data.get('Index class', '')\n",
    "                        index_prefix = data.get('Index prefix', '')\n",
    "                        index_name = data.get('Index name', '')\n",
    "                        value_2019 = data.get('2019', '')\n",
    "                        value_2020 = data.get('2020', '')\n",
    "                        value_2021 = data.get('2021', '')\n",
    "                        value_2022 = data.get('2022', '')\n",
    "                        value_2023 = data.get('2023', '')\n",
    "                        writer.writerow([file_name, index_class, index_prefix, index_name, value_2019, value_2020, value_2021, value_2022, value_2023])\n",
    "                    else:\n",
    "                        # 处理意外的 JSON 结构\n",
    "                        print(f\"Unexpected JSON structure for {file_name}\")\n",
    "                        # 根据需求决定是否跳过或记录空值\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSON decode error for {file_name}: {e}\")\n",
    "                    # 根据需求决定是否跳过或记录空值\n",
    "            else:\n",
    "                # 如果 extracted_data 为空，则跳过\n",
    "                print(f\"Extracted data is empty for {file_name}\")\n",
    "                # 不进行任何写入操作\n",
    "\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4863c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 设置 OpenAI API 密钥\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model_name = \"gpt-4\"\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(model_name, exist_ok=True)\n",
    "output_path = f\"{model_name}/processed_data.csv\"\n",
    "\n",
    "# 提取图片的路径\n",
    "extracted_images_dir = r'./output/ST-Engineering-Sustainability-Report2020/rendered_pages'\n",
    "\n",
    "# 编码图片的函数\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# 系统提示和用户指令\n",
    "system_prompt = 'You are an expert in data extraction, specializing in extracting tabular data from images.'\n",
    "text_content = '''\n",
    "Extract meaningful data, especially numbers and related textual information, \n",
    "from the image and convert it into a structured \n",
    "JSON format with the following fields: \"Index class\", \"Index prefix\", \"Index name\", \n",
    "\"2019\", \"2020\", \"2021\", \"2022\", and \"2023\". \n",
    "If any field does not exist, set its value to null. \n",
    "Please retain all data in its original format, especially numeric values, and avoid any translation or conversion to other languages. \n",
    "Skip extraction if there is no meaningful data in the image.\n",
    "'''\n",
    "\n",
    "# 写入 CSV 文件\n",
    "with open(output_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # 更新列标题\n",
    "    writer.writerow([\"Image Name\", \"Index class\", \"Index prefix\", \"Index name\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"])\n",
    "\n",
    "    if os.path.exists(extracted_images_dir):\n",
    "        image_files = [f for f in os.listdir(extracted_images_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "        if not image_files:\n",
    "            print(f\"No image files found in the directory: {extracted_images_dir}\")\n",
    "        else:\n",
    "            for file_name in tqdm(image_files, desc=\"Processing images\"):\n",
    "                image_path = os.path.join(extracted_images_dir, file_name)\n",
    "                if os.path.isfile(image_path):\n",
    "                    base64_image = encode_image(image_path)\n",
    "\n",
    "                    # 创建对话消息\n",
    "                    messages = [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": text_content},\n",
    "                        {\"role\": \"user\", \"content\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                    ]\n",
    "\n",
    "                    try:\n",
    "                        # 调用 OpenAI API\n",
    "                        resp = openai.ChatCompletion.create(\n",
    "                            model=model_name,\n",
    "                            messages=messages,\n",
    "                            temperature=0.0\n",
    "                        )\n",
    "                        extracted_data = resp.choices[0].message['content']\n",
    "                        print(f\"Extracted data for {file_name}: {extracted_data}\")\n",
    "\n",
    "                        if extracted_data:\n",
    "                            try:\n",
    "                                data = json.loads(extracted_data)\n",
    "                                if isinstance(data, list):\n",
    "                                    for row in data:\n",
    "                                        index_class = row.get('Index class', '')\n",
    "                                        index_prefix = row.get('Index prefix', '')\n",
    "                                        index_name = row.get('Index name', '')\n",
    "                                        value_2019 = row.get('2019', '')\n",
    "                                        value_2020 = row.get('2020', '')\n",
    "                                        value_2021 = row.get('2021', '')\n",
    "                                        value_2022 = row.get('2022', '')\n",
    "                                        value_2023 = row.get('2023', '')\n",
    "                                        writer.writerow([file_name, index_class, index_prefix, index_name, value_2019, value_2020, value_2021, value_2022, value_2023])\n",
    "                                elif isinstance(data, dict):\n",
    "                                    # 如果数据是单个字典\n",
    "                                    index_class = data.get('Index class', '')\n",
    "                                    index_prefix = data.get('Index prefix', '')\n",
    "                                    index_name = data.get('Index name', '')\n",
    "                                    value_2019 = data.get('2019', '')\n",
    "                                    value_2020 = data.get('2020', '')\n",
    "                                    value_2021 = data.get('2021', '')\n",
    "                                    value_2022 = data.get('2022', '')\n",
    "                                    value_2023 = data.get('2023', '')\n",
    "                                    writer.writerow([file_name, index_class, index_prefix, index_name, value_2019, value_2020, value_2021, value_2022, value_2023])\n",
    "                                else:\n",
    "                                    # 处理意外的 JSON 结构\n",
    "                                    print(f\"Unexpected JSON structure for {file_name}\")\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"JSON decode error for {file_name}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
